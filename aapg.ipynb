{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb54441b-9bab-4068-ae12-2b1cad00efce",
   "metadata": {
    "editable": true,
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# The Fundamentals of Generative AI and Machine Learning That Pertain to Geologists and Engineers\n",
    "\n",
    "### John T. Foster  \n",
    "Hildbrand Department of Petroleum Engineering  \n",
    "The University of Texas at Austin  \n",
    "<a href=\"mailto:john.foster@utexas.edu\">john.foster@utexas.e</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291e07c-b80c-4172-8049-f1d18b9bb17b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Machine Learning 101\n",
    "\n",
    "$$\n",
    "{\\vec{y}} = f(\\vec{X}_1, \\vec{X}_2, \\ldots, \\vec{X}_n)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\min \\sum_i \\left(y_i - \\hat{y}_i \\right)^2\n",
    "$$\n",
    "\n",
    "|||\n",
    "|:-|:-|\n",
    "|${\\vec{y}}$| response features (outputs)|\n",
    "|${X_1, X_2, \\ldots X_n}$| predictor features (inputs)|\n",
    "|$f$| estimator (model)|\n",
    "|$\\hat{y}$| data |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb83f6-c06c-4c8b-a138-8b5a8b971cce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Example: Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effcd845-e4e2-4f7f-af7d-9f0865c9c591",
   "metadata": {
    "editable": true,
    "hide_input": true,
    "rise": {
     "hide_input": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b98a47d4624b739fd66e3df4806f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Polynomial Order:', options=(1, 3, 5, 7, 9), style=Descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010fd24537fc4f0ca3fb991242c5993d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Use the widget backend for Matplotlib\n",
    "%matplotlib widget\n",
    "\n",
    "# Turn off interactive mode to suppress auto-plotting\n",
    "plt.ioff()\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.iloc[:, 0].values.reshape(-1, 1)\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Define fixed train/test indices for realization 1\n",
    "FIXED_TRAIN_INDICES = [0, 2, 3, 4, 6, 7, 9, 11]\n",
    "FIXED_TEST_INDICES = [1, 5, 8, 10]\n",
    "\n",
    "# Create widgets\n",
    "poly_order = widgets.Dropdown(\n",
    "    options=[1, 3, 5, 7, 9],\n",
    "    value=1,\n",
    "    description='Polynomial Order:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "split_realization = widgets.Dropdown(\n",
    "    options=[1, 2, 3, 4, 5],\n",
    "    value=1,\n",
    "    description='Test/Train Split Realization:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Output widgets for displaying the plot and LaTeX equation\n",
    "output = widgets.Output()\n",
    "equation_output = widgets.Output()\n",
    "\n",
    "# Arrange dropdowns in a vertical box\n",
    "selectors = widgets.VBox([poly_order, split_realization])\n",
    "\n",
    "# Right-justifying the equation, making the container responsive, and enabling scrolling\n",
    "equation_container = widgets.Box(\n",
    "    [equation_output],\n",
    "    layout=widgets.Layout(\n",
    "        display='flex',\n",
    "        align_items='center',  # Vertically center the equation\n",
    "        justify_content='flex-end',  # Right justify the equation\n",
    "        height='auto',  # Match the height of the selectors\n",
    "        overflow='auto',  # Enable scrolling if the equation is too wide\n",
    "        padding='10px'  # Optional padding for spacing\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ensure the height of the container matches the height of the selector box\n",
    "selectors.layout = widgets.Layout(\n",
    "    height='auto',  # Automatically adjust to fit the content\n",
    "    padding='10px'  # Optional: Add padding for spacing\n",
    ")\n",
    "\n",
    "def get_train_test_indices(realization):\n",
    "    \"\"\"Generate train and test indices based on the realization number.\"\"\"\n",
    "    if realization == 1:\n",
    "        return FIXED_TRAIN_INDICES, FIXED_TEST_INDICES\n",
    "    else:\n",
    "        all_indices = np.arange(len(X))\n",
    "        train_indices, test_indices = train_test_split(all_indices, test_size=4, random_state=realization)\n",
    "        return train_indices, test_indices\n",
    "\n",
    "def fit_polynomial(X_train, y_train, X_test, degree):\n",
    "    \"\"\"Fit a polynomial of the given degree and return predictions.\"\"\"\n",
    "    coeffs = np.polyfit(X_train.flatten(), y_train, degree)\n",
    "    poly = np.poly1d(coeffs)\n",
    "    y_train_pred = poly(X_train)\n",
    "    y_test_pred = poly(X_test)\n",
    "    return poly, coeffs, y_train_pred, y_test_pred\n",
    "\n",
    "\n",
    "def plot_results(X, y, train_idx, test_idx, poly_order):\n",
    "    \"\"\"Plot the polynomial fit and residuals.\"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Fit polynomial and get predictions\n",
    "    poly, coeffs, y_train_pred, y_test_pred = fit_polynomial(X_train, y_train, X_test, poly_order)\n",
    "    \n",
    "    # Create a new figure\n",
    "    fig = plt.figure(figsize=(12*3/4, 8*3/4))\n",
    "    grid = plt.GridSpec(2, 2, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # First row: Data and polynomial curve\n",
    "    ax1 = fig.add_subplot(grid[0, :])\n",
    "    X_smooth = np.linspace(X.min(), X.max(), 200).reshape(-1, 1)\n",
    "    ax1.plot(X_smooth, poly(X_smooth), 'b-', label=f'Polynomial (order {poly_order})')\n",
    "    ax1.plot(X_train, y_train, 'ko', label='Training data')\n",
    "    ax1.plot(X_test, y_test, 'ro', label='Test data')\n",
    "    ax1.set_xlabel(r'Depth, $D$ (m)')\n",
    "    ax1.set_ylabel(r'Permeability, $\\kappa$ (mD)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Second row, left: Training residuals (Stem plot)\n",
    "    ax2 = fig.add_subplot(grid[1, 0])\n",
    "    train_residuals = y_train - y_train_pred.flatten()\n",
    "    ax2.stem(\n",
    "        X_train.flatten(),\n",
    "        train_residuals,\n",
    "        linefmt='k-',\n",
    "        markerfmt='ko',\n",
    "        basefmt='b-'\n",
    "    )\n",
    "    ax2.set_ylim([-1000, 1000])\n",
    "    ax2.set_xlabel(r'Depth, $D$ (m)')\n",
    "    ax2.set_ylabel(r'Residual Error')\n",
    "    ax2.set_title('Training Set')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Second row, right: Test residuals (Stem plot)\n",
    "    ax3 = fig.add_subplot(grid[1, 1])\n",
    "    test_residuals = y_test - y_test_pred.flatten()\n",
    "    ax3.stem(\n",
    "        X_test.flatten(),\n",
    "        test_residuals,\n",
    "        linefmt='r-',\n",
    "        markerfmt='ro',\n",
    "        basefmt='b-'\n",
    "    )\n",
    "    ax3.set_ylim([-1000, 1000])\n",
    "    ax3.set_xlabel(r'Depth, $D$ (m)')\n",
    "    ax3.set_ylabel(r'Residual Error')\n",
    "    ax3.set_title('Test Set')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    return fig, coeffs\n",
    "\n",
    "def format_polynomial(coeffs):\n",
    "    \"\"\"Format the polynomial coefficients into a LaTeX equation.\"\"\"\n",
    "    terms = []\n",
    "    degree = len(coeffs) - 1\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        if abs(coeff) < 1e-6:  # Skip near-zero terms\n",
    "            continue\n",
    "        # Format each term\n",
    "        power = degree - i\n",
    "        if power == 0:\n",
    "            terms.append(f'{coeff:.2f}')\n",
    "        elif power == 1:\n",
    "            terms.append(f\"{coeff:.2f}D\")\n",
    "        else:\n",
    "            terms.append(f\"{coeff:.2f}D^{power}\")\n",
    "    equation = \" + \".join(terms).replace(\" + -\", \" - \")  # Clean up the signs\n",
    "    return f\"\\\\kappa = {equation}\"\n",
    "\n",
    "def update_plot(change=None):\n",
    "    \"\"\"Update the plot and LaTeX equation.\"\"\"\n",
    "    with output:\n",
    "        # Clear any previous output in the widget\n",
    "        output.clear_output(wait=True)\n",
    "        \n",
    "        # Close all previous matplotlib figures to prevent duplication\n",
    "        plt.close(\"all\")\n",
    "        \n",
    "        # Get the current train/test indices and plot the results\n",
    "        train_idx, test_idx = get_train_test_indices(split_realization.value)\n",
    "        fig, coeffs = plot_results(X, y, train_idx, test_idx, poly_order.value)\n",
    "        \n",
    "        # Display the plot explicitly\n",
    "        display(fig)\n",
    "    \n",
    "    with equation_output:\n",
    "        # Clear any previous output in the equation widget\n",
    "        equation_output.clear_output(wait=True)\n",
    "        \n",
    "        # Format the polynomial equation and display it\n",
    "        equation = format_polynomial(coeffs)\n",
    "        display(Math(equation))\n",
    "\n",
    "# Set up widget observers\n",
    "poly_order.observe(update_plot, names='value')\n",
    "split_realization.observe(update_plot, names='value')\n",
    "\n",
    "# Arrange the selectors vertically and add the equation to the right\n",
    "layout = widgets.HBox([selectors, equation_container])  # Horizontal layout: dropdowns on the left, right-aligned equation on the right\n",
    "\n",
    "# Display the layout and the output widget\n",
    "display(layout, output)\n",
    "\n",
    "# Display the initial plot and equation (inside the output widgets)\n",
    "with output:\n",
    "    update_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd66873-a906-43bb-a059-f35ee201a178",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fdadf-29e2-4c4c-a565-f1de36c4a272",
   "metadata": {},
   "source": [
    "<img src=\"aapg_nn.png\" alt=\"Example Image\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34d023-320f-4476-9a24-75bd8301d794",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\vec{Y} &= \\sigma(\\vec{Z} \\cdot \\vec{w}_Z + b_Z) \\\\\n",
    "        &= \\sigma(\\sigma(\\vec{X} \\cdot \\vec{w}_X + b_X) \\cdot w_Z + b_Z)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|$\\sigma$|activation function, i.e. $\\tanh$, ReLU|\n",
    "|$\\vec{w}_Z, \\vec{w}_X$| weights |\n",
    "|$b_Z, b_X$| biases |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e55a2-3782-4b55-9b5f-701ed709ce9e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Neural Networks (cont'd)\n",
    "\n",
    "## Architectures\n",
    "\n",
    "* Feed foward\n",
    "* Recurrent NN\n",
    "* LSTM\n",
    "* Convolution\n",
    "* Autoencoder\n",
    "* Transformer\n",
    "\n",
    "## Parameters\n",
    "\n",
    "* Weights and Biases\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "* Number of layers\n",
    "* Number of neurons\n",
    "* Activation functions\n",
    "* Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a34631-9a10-4bfa-b737-9e1bf2a686dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Example: Seismic Downscaling\n",
    "\n",
    "<img src=\"aapg_downscaling.png\" alt=\"Example Image\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd1a53-c8f0-46f3-8957-f078e80d6c1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Transformers / Large Language Models (i.e. ChatGPT)\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"aapg_transformers.png\" alt=\"Example Image\" width=\"600\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "AAPG",
   "language": "python",
   "name": "aapg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "rise": {
   "controls": false,
   "custom_styles": "rise.css",
   "footer": "<center><h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AAPG Workshop on Generative AI, Machine Learning and Analytics for Subsurface Energy &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Houston, TX &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 2024</h3></center>",
   "slideNumber": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
